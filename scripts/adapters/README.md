# è¯å…¸é€‚é…å™¨å¼€å‘æŒ‡å—

## æ¦‚è¿°

æ¯ä¸ªç²¤è¯­è¯å…¸çš„æ•°æ®ç»“æ„éƒ½ä¸ç›¸åŒï¼Œå› æ­¤éœ€è¦ä¸ºæ¯ä¸ªè¯å…¸å¼€å‘ä¸“é—¨çš„**é€‚é…å™¨ï¼ˆAdapterï¼‰**ã€‚

é€‚é…å™¨çš„ä½œç”¨æ˜¯å°†è¯å…¸ç‰¹æœ‰çš„ CSV æ ¼å¼è½¬æ¢ä¸ºé¡¹ç›®ç»Ÿä¸€çš„ `DictionaryEntry` æ ¼å¼ã€‚

---

## é€‚é…å™¨ç»“æ„

ä¸€ä¸ªæ ‡å‡†é€‚é…å™¨åŒ…å«ä»¥ä¸‹éƒ¨åˆ†ï¼š

```javascript
// 1. è¯å…¸å…ƒæ•°æ®
export const DICTIONARY_INFO = {
  id: 'dict-id',
  name: 'è¯å…¸åç§°',
  dialect: { name: 'å¹¿å·è¯', region_code: 'GZ' },
  // ...
}

// 2. å¿…å¡«å­—æ®µ
export const REQUIRED_FIELDS = ['field1', 'field2']

// 3. å•è¡Œè½¬æ¢å‡½æ•°
export function transformRow(row) {
  // å°† CSV è¡Œè½¬æ¢ä¸º DictionaryEntry
}

// 4. æ‰¹é‡è½¬æ¢å‡½æ•°
export function transformAll(rows) {
  // æ‰¹é‡å¤„ç†ï¼Œè¿”å› { entries, errors }
}

// 5. åå¤„ç†å‡½æ•°ï¼ˆå¯é€‰ï¼‰
export function aggregateEntries(entries) {
  // èšåˆå¤šä¹‰é¡¹ç­‰
}
```

---

## å¼€å‘æ­¥éª¤

### Step 1: åˆ†æåŸå§‹æ•°æ®

å‡è®¾ä½ æœ‰ä¸€ä¸ªæ–°è¯å…¸çš„ CSV æ•°æ®ï¼š

```csv
id,word,pronunciation,definition,example,dialect_area
1,éšä»”,leng3 zai2,å¸…å“¥,ä½ å€‹ä»”å¥½éšä»”,å¹¿å·
```

**éœ€è¦åˆ†æ**:
- å“ªäº›å­—æ®µæ˜¯å¿…å¡«çš„ï¼Ÿ
- å“ªäº›å­—æ®µåŒ…å«å¤šä¸ªå€¼ï¼ˆéœ€è¦åˆ†å‰²ï¼‰ï¼Ÿ
- é‡Šä¹‰å’Œä¾‹å¥æ˜¯å¦æ··åˆï¼Ÿ
- æœ‰æ²¡æœ‰ç‰¹æ®Šæ ‡è®°æˆ–æ ¼å¼ï¼Ÿ

### Step 2: åˆ›å»ºé€‚é…å™¨æ–‡ä»¶

åœ¨ `scripts/adapters/` ç›®å½•åˆ›å»ºæ–°æ–‡ä»¶ï¼Œå‘½åè§„èŒƒï¼š`è¯å…¸ID.js`

ä¾‹å¦‚ï¼š`scripts/adapters/my-new-dict.js`

### Step 3: å®šä¹‰å…ƒæ•°æ®

```javascript
export const DICTIONARY_INFO = {
  id: 'my-new-dict',
  name: 'æˆ‘çš„æ–°è¯å…¸',
  dialect: {
    name: 'å¹¿å·è¯',
    region_code: 'GZ'
  },
  source_book: 'æˆ‘çš„æ–°è¯å…¸',
  author: 'ä½œè€…å',
  publisher: 'å‡ºç‰ˆç¤¾',
  year: 2000
}

export const REQUIRED_FIELDS = ['id', 'word', 'pronunciation', 'definition']
```

### Step 4: å®ç° transformRow

```javascript
import {
  generateKeywords,
  cleanHeadword
} from '../utils/text-processor.js'

// æ³¨æ„ï¼šç®€ç¹ä½“è½¬æ¢å·²ç§»è‡³è¿è¡Œæ—¶å¤„ç†ï¼Œæ— éœ€åœ¨é€‚é…å™¨ä¸­å¤„ç†

export function transformRow(row) {
  // 1. å¤„ç†è¯å¤´
  const headwordInfo = cleanHeadword(row.word)
  
  // 2. å¤„ç†ç²¤æ‹¼
  const jyutpingArray = row.pronunciation
    .split(/[,;]/)
    .map(j => j.trim())
    .filter(j => j)
  
  // 3. æ„å»ºè¯æ¡
  const entry = {
    id: `${DICTIONARY_INFO.id}_${String(row.id).padStart(6, '0')}`,
    source_book: DICTIONARY_INFO.source_book,
    source_id: row.id,
    
    dialect: DICTIONARY_INFO.dialect,
    
    headword: {
      display: row.word,
      search: headwordInfo.normalized,
      normalized: headwordInfo.normalized,
      is_placeholder: headwordInfo.isPlaceholder || false
    },
    
    phonetic: {
      original: row.pronunciation,
      jyutping: jyutpingArray
    },
    
    entry_type: guessEntryType(headwordInfo.normalized),
    
    senses: [
      {
        definition: row.definition,
        examples: row.example ? [{ text: row.example }] : []
      }
    ],
    
    meta: {
      // è¯å…¸ç‰¹æœ‰å­—æ®µæ”¾è¿™é‡Œ
      dialect_area: row.dialect_area
    },
    
    created_at: new Date().toISOString()
  }
  
  // 4. ç”Ÿæˆæœç´¢å…³é”®è¯
  entry.keywords = generateKeywords(entry)
  
  return entry
}
```

### Step 5: å®ç° transformAll

```javascript
export function transformAll(rows) {
  const entries = []
  const errors = []
  
  rows.forEach((row, index) => {
    try {
      const entry = transformRow(row)
      entries.push(entry)
    } catch (error) {
      errors.push({
        row: index + 2,
        error: error.message,
        data: row
      })
    }
  })
  
  return { entries, errors }
}
```

### Step 6: å®ç°èšåˆï¼ˆå¯é€‰ï¼‰

å¦‚æœä½ çš„è¯å…¸æœ‰å¤šä¹‰é¡¹éœ€è¦èšåˆï¼š

```javascript
export function aggregateEntries(entries) {
  // å®ç°èšåˆé€»è¾‘
  // å‚è€ƒ gz-practical-classified.js
}
```

### Step 7: æ³¨å†Œé€‚é…å™¨

åœ¨ `scripts/csv-to-json.js` ä¸­æ·»åŠ ä½ çš„é€‚é…å™¨ï¼š

```javascript
const ADAPTERS = {
  'gz-practical-classified': () => import('./adapters/gz-practical-classified.js'),
  'my-new-dict': () => import('./adapters/my-new-dict.js'), // æ·»åŠ è¿™è¡Œ
}
```

### Step 8: æµ‹è¯•

```bash
# è¿è¡ŒéªŒè¯
node scripts/validate.js data/processed/my-dict.csv

# è¿è¡Œè½¬æ¢
node scripts/csv-to-json.js \
  --dict my-new-dict \
  --input data/processed/my-dict.csv

# ç¤ºä¾‹ï¼šè½¬æ¢å¹¿å·è¯ä¿—è¯­è¯å…¸
node scripts/csv-to-json.js \
  --dict gz-colloquialisms \
  --input data/processed/gz-colloquialisms.csv \
  --output public/dictionaries/gz-colloquialisms.json
```

---

## ç¤ºä¾‹ 1ï¼šå®ç”¨å¹¿å·è¯åˆ†ç±»è¯å…¸

å‚è€ƒ `gz-practical-classified.js`ï¼Œå®ƒå±•ç¤ºäº†å¦‚ä½•å¤„ç†ï¼š

1. **ç‰¹æ®Šæ ‡è®°** (`*å“‹1`)
   ```javascript
   const headwordInfo = cleanHeadword(row.words)
   ```

2. **æ··åˆçš„é‡Šä¹‰å’Œä¾‹å¥**
   ```javascript
   const { definition, examples } = parseExamples(row.meanings)
   ```

3. **ä¸‰çº§åˆ†ç±»**
   ```javascript
   const categories = [row.category_1, row.category_2, row.category_3]
   const categoryPath = categories.filter(c => c).join(' > ')
   ```

4. **æ–¹æ‹¬å·å¤‡æ³¨**
   ```javascript
   meta: {
     notes: parseNote(row.note)
   }
   ```

## ç¤ºä¾‹ 2ï¼šç²µå…¸ (words.hk)

å‚è€ƒ `hk-cantowords.js`ï¼Œå®ƒå±•ç¤ºäº†å¦‚ä½•å¤„ç†ï¼š

### CSV æ ¼å¼ç‰¹ç‚¹

ç²µå…¸ CSV æ ¼å¼ç‰¹æ®Šï¼Œç¬¬ä¸€è¡Œæ˜¯ç‰ˆæƒå£°æ˜ï¼ˆè¢«å½“ä½œè¡¨å¤´ï¼‰ï¼Œéœ€è¦é¢„å¤„ç†ï¼š

```javascript
export function preprocessRows(rows) {
  return rows.map(row => {
    const keys = Object.keys(row)
    const longKey = keys.find(k => k.length > 100) || keys[2]
    
    return {
      id: row[''] || '',
      headwords_jyutping: row['_1'] || '',
      content: row[longKey] || '',
      review_status: row['__parsed_extra']?.[1] || '',
      publish_status: row['__parsed_extra']?.[2] || ''
    }
  })
}
```

### æ ¸å¿ƒåŠŸèƒ½å®ç°

1. **å¤æ‚çš„ç»“æ„åŒ–å†…å®¹**ï¼ˆåŒ…å«å¤šç§æ ‡è®°ï¼‰
   
   å†…å®¹æ ¼å¼ï¼š`(pos:xxx)` `<explanation>` `<eg>` `yue:` `eng:` `----`
   
   ```javascript
   function parseContent(content) {
     // æŒ‰ ---- åˆ†å‰²å¤šä¸ªä¹‰é¡¹
     const senseParts = content.split(/\n?----\n?/).filter(p => p.trim())
     
     senseParts.forEach(sensePart => {
       // æå–è¯æ€§ï¼š(pos:èªå¥)
       const posMatch = sensePart.match(/\(pos:([^)]+)\)/)
       
       // åˆ†å‰²é‡Šä¹‰å’Œä¾‹å¥éƒ¨åˆ†
       const parts = sensePart.split(/<eg>/i)
       const explanationPart = parts[0]
       const examplePart = parts[1]
       
       // æå– yue: å’Œ eng: å†…å®¹
       const yueMatch = explanationPart.match(/yue:(.+?)(?=\neng:|$)/s)
       const engMatch = explanationPart.match(/eng:(.+?)$/s)
     })
   }
   ```

2. **å¤šä¸ªè¯å¤´å˜ä½“**ï¼ˆç”¨å†’å·å’Œé€—å·åˆ†éš”ï¼‰
   
   æ ¼å¼ï¼š`å°æ„æ€:siu2 ji3 si1,å°å°æ„æ€:siu2 siu2 ji3 si1`
   
   ```javascript
   function parseHeadwordsWithJyutping(headwordsStr) {
     const variants = []
     const parts = headwordsStr.split(',').map(p => p.trim()).filter(p => p)
     
     parts.forEach(part => {
       const colonIndex = part.indexOf(':')
       if (colonIndex > 0) {
         variants.push({
           headword: part.substring(0, colonIndex).trim(),
           jyutping: part.substring(colonIndex + 1).trim()
         })
       }
     })
     return variants
   }
   ```

3. **å®¡æ ¸å’Œå…¬å¼€çŠ¶æ€**
   ```javascript
   meta: {
     review_status: reviewStatus,
     is_reviewed: !reviewStatus.includes('UNREVIEWED'),
     publish_status: publishStatus,
     is_public: !publishStatus.includes('æœªå…¬é–‹')
   }
   ```

4. **å¤šè¯­è¨€é‡Šä¹‰å’Œä¾‹å¥**ï¼ˆç²¤è¯­å’Œè‹±è¯­ï¼‰
   ```javascript
   // ä» yue: å’Œ eng: æ ‡è®°ä¸­æå–
   const yueMatch = text.match(/yue:(.+?)(?=\neng:|$)/s)
   const engMatch = text.match(/eng:(.+?)$/s)
   
   if (yueMatch) {
     sense.definition = yueMatch[1].trim()
     if (engMatch) {
       sense.definition += ` (${engMatch[1].trim()})`
     }
   }
   ```

### ä½¿ç”¨è¯´æ˜

```bash
# è½¬æ¢ç²µå…¸æ•°æ®
npm run build:data:hk

# æˆ–å®Œæ•´å‘½ä»¤
node scripts/csv-to-json.js \
  --dict hk-cantowords \
  --input data/processed/hk-cantowords.csv

# æµ‹è¯•å°æ•°æ®é›†
head -n 1000 data/processed/hk-cantowords.csv > /tmp/test.csv
node scripts/csv-to-json.js --dict hk-cantowords --input /tmp/test.csv
```

### æ³¨æ„äº‹é¡¹

âš ï¸ **é‡è¦**ï¼šç²µå…¸æ•°æ®é‡‡ç”¨ã€Šéå•†ä¸šå¼€æ”¾èµ„æ–™æˆæƒåè®® 1.0ã€‹
- ç‰ˆæƒæŒæœ‰äººï¼šHong Kong Lexicography Limited
- å…è®¸éå•†ä¸šä½¿ç”¨ï¼Œå•†ä¸šä½¿ç”¨éœ€æˆæƒ
- è¯¦è§ï¼šhttps://words.hk/base/hoifong/

## ç¤ºä¾‹ 3: Wiktionaryç²¤è¯­è¯æ¡

å‚è€ƒ `wiktionary-cantonese.js`ï¼Œå®ƒå±•ç¤ºäº†å¦‚ä½•å¤„ç† **JSONL æ ¼å¼** æ•°æ®ï¼ˆè€ŒéCSVï¼‰ï¼š

### æ•°æ®æ ¼å¼ç‰¹ç‚¹

Wiktionary æ•°æ®ä¸º JSONL æ ¼å¼ï¼ˆæ¯è¡Œä¸€ä¸ªJSONå¯¹è±¡ï¼‰ï¼Œéœ€è¦ä½¿ç”¨ä¸“é—¨çš„ `jsonl-to-json.js` è„šæœ¬ã€‚

```javascript
{
  "word": "book",
  "lang": "Chinese",
  "pos": "verb",
  "sounds": [...],
  "senses": [...],
  "forms": [...],
  "etymology_text": "..."
}
```

### æ ¸å¿ƒåŠŸèƒ½å®ç°

1. **ç­›é€‰ç²¤è¯­è¯æ¡**
   ```javascript
   function isCantoneseEntry(entry) {
     // æ£€æŸ¥soundsä¸­æ˜¯å¦æœ‰Cantoneseæ ‡ç­¾
     if (entry.sounds && Array.isArray(entry.sounds)) {
       const hasCantoneseSound = entry.sounds.some(sound => 
         sound.tags?.some(tag => 
           tag?.toLowerCase().includes('cantonese')
         )
       )
       if (hasCantoneseSound) return true
     }
     return false
   }
   ```

2. **æå–ç²¤æ‹¼ï¼ˆJyutpingï¼‰**
   ```javascript
   function extractJyutping(sounds) {
     const jyutpingSet = new Set()
     
     sounds.forEach(sound => {
       if (sound.tags) {
         const hasCantonese = sound.tags.some(tag => 
           tag?.toLowerCase().includes('cantonese')
         )
         const hasJyutping = sound.tags.some(tag => 
           tag?.toLowerCase().includes('jyutping')
         )
         
         if (hasCantonese && hasJyutping && sound.zh_pron) {
           // æ ‡å‡†åŒ–å£°è°ƒæ ‡è®°ï¼šÂ¹Â²Â³ â†’ 123
           let normalized = sound.zh_pron
             .replace(/Â¹/g, '1')
             .replace(/Â²/g, '2')
             // ...
           jyutpingSet.add(normalized)
         }
       }
     })
     
     return Array.from(jyutpingSet)
   }
   ```

3. **æå–IPAéŸ³æ ‡**
   ```javascript
   function extractIPA(sounds) {
     for (const sound of sounds) {
       if (sound.tags?.some(tag => 
         tag?.toLowerCase().includes('cantonese')
       ) && sound.ipa) {
         return sound.ipa
       }
     }
     return null
   }
   ```

4. **è¯æ€§æ˜ å°„ï¼ˆè‹±æ–‡â†’ä¸­æ–‡ï¼‰**
   ```javascript
   const POS_MAP = {
     'noun': 'åè¯',
     'verb': 'åŠ¨è¯',
     'adj': 'å½¢å®¹è¯',
     'adv': 'å‰¯è¯',
     // ...
   }
   
   const posChinese = POS_MAP[entry.pos?.toLowerCase()] || entry.pos
   ```

5. **æå–å¼‚ä½“å­—**
   ```javascript
   function extractVariants(forms) {
     const variants = []
     forms?.forEach(form => {
       if (form.tags?.includes('alternative')) {
         variants.push(form.form)
       }
     })
     return variants
   }
   ```

6. **å¤„ç†æ ‡ç­¾ç³»ç»Ÿ**
   ```javascript
   function extractRegion(tags) {
     for (const tag of tags) {
       const lower = tag?.toLowerCase()
       if (lower?.includes('hong-kong')) return 'é¦™æ¸¯'
       if (lower?.includes('guangzhou')) return 'å¹¿å·'
     }
     return null
   }
   
   function extractRegister(tags) {
     for (const tag of tags) {
       const lower = tag?.toLowerCase()
       if (lower?.includes('colloquial')) return 'å£è¯­'
       if (lower?.includes('slang')) return 'ä¿šè¯­'
     }
     return null
   }
   ```

### ä½¿ç”¨è¯´æ˜

```bash
# å®Œæ•´è½¬æ¢ï¼ˆå¤„ç†æ‰€æœ‰è¯æ¡ï¼‰
npm run build:data:wiktionary

# æµ‹è¯•æ¨¡å¼ï¼ˆåªå¤„ç†å‰1000æ¡ï¼‰
npm run build:data:wiktionary:test

# æˆ–å®Œæ•´å‘½ä»¤
node scripts/jsonl-to-json.js \
  --dict wiktionary-cantonese \
  --input data/processed/wiktionary_cantonese_entries.jsonl

# é™åˆ¶å¤„ç†æ•°é‡ï¼ˆæµ‹è¯•ç”¨ï¼‰
node scripts/jsonl-to-json.js \
  --dict wiktionary-cantonese \
  --input data/processed/wiktionary_cantonese_entries.jsonl \
  --limit 1000
```

### ç‰¹æ®Šå­—æ®µè¯´æ˜

| å­—æ®µ | è¯´æ˜ | å¤„ç†æ–¹å¼ |
|------|------|---------|
| `sounds` | å‘éŸ³æ•°ç»„ | ç­›é€‰Cantonese+Jyutpingæ ‡ç­¾ |
| `ipa` | IPAéŸ³æ ‡ | ä½œä¸º`original`å­—æ®µå±•ç¤º |
| `pos` | è¯æ€§ï¼ˆè‹±æ–‡ï¼‰ | æ˜ å°„ä¸ºä¸­æ–‡è¯æ€§ |
| `forms` | è¯å½¢å˜åŒ– | æå–alternativeæ ‡è®°çš„å¼‚ä½“å­— |
| `etymology_text` | è¯æº | ä¿å­˜åˆ°meta.etymology |
| `tags` | æ ‡ç­¾ | è¯†åˆ«åœ°åŒºå’Œè¯­åŸŸä¿¡æ¯ |
| `senses` | é‡Šä¹‰æ•°ç»„ | åŒ…å«glossesã€examplesç­‰ |

### æ³¨æ„äº‹é¡¹

âš ï¸ **é‡è¦**ï¼šWiktionaryæ•°æ®é‡‡ç”¨ CC BY-SA 4.0 åè®®
- å…è®¸è‡ªç”±ä½¿ç”¨å’Œä¿®æ”¹
- éœ€ä¿ç•™ç½²åï¼šWiktionary contributors
- è¯¦è§ï¼šhttps://creativecommons.org/licenses/by-sa/4.0/

### æ•°æ®è´¨é‡è¯´æ˜

- âœ… å‘éŸ³å‡†ç¡®ï¼šJyutping + IPAåŒé‡æ ‡æ³¨
- âœ… è¯æºä¸°å¯Œï¼šå¤§é‡è¯æºä¿¡æ¯
- âœ… æ ‡ç­¾å®Œå–„ï¼šåœ°åŒºã€è¯­åŸŸç­‰æ ‡ç­¾æ¸…æ™°
- âš ï¸ è¦†ç›–å‚å·®ï¼šå¹¶éæ‰€æœ‰è¯æ¡éƒ½æœ‰ç²¤è¯­å‘éŸ³
- âš ï¸ éœ€ç­›é€‰ï¼šä»å¤§é‡Chineseè¯æ¡ä¸­ç­›é€‰ç²¤è¯­ç›¸å…³å†…å®¹

## ç¤ºä¾‹ 4ï¼šå¹¿å·è¯ä¿—è¯­è¯å…¸

å‚è€ƒ `gz-colloquialisms.js`ï¼Œå®ƒå±•ç¤ºäº†å¦‚ä½•å¤„ç†ï¼š

1. **æ­‡åè¯­ç»“æ„**ï¼ˆå‰ååŠå¥ç”¨é€—å·åˆ†éš”ï¼‰
   ```javascript
   function detectColloquialismType(phrase) {
     if (phrase.includes('ï¼Œ') || phrase.includes(',')) {
       const parts = phrase.split(/[ï¼Œ,]/)
       if (parts.length === 2 && parts[0].length > 2 && parts[1].length > 2) {
         return 'xiehouyu' // æ­‡åè¯­
       }
     }
     return 'idiom'
   }
   ```

2. **å¤šä¹‰é¡¹èšåˆ**ï¼ˆæŒ‰ index å’Œ sense_numberï¼‰
   ```javascript
   export function aggregateEntries(entries) {
     // æŒ‰ index åˆ†ç»„
     const grouped = new Map()
     entries.forEach(entry => {
       const index = entry.meta._originalIndex
       if (!grouped.has(index)) {
         grouped.set(index, [])
       }
       grouped.get(index).push(entry)
     })
     // èšåˆæ¯ç»„çš„ senses
     // ...
   }
   ```

3. **ä¿ç•™å¹¿å·è¯æ‹¼éŸ³æ–¹æ¡ˆ**ï¼ˆgwongping ä½œä¸ºåŸå§‹æ³¨éŸ³ï¼‰
   ```javascript
   phonetic: {
     original: row.gwongping || row.jyutping,
     jyutping: jyutpingArray
   },
   meta: {
     gwongping: row.gwongping || null
   }
   ```

4. **ä¿—è¯­ç±»å‹åˆ†ç±»**
   ```javascript
   meta: {
     colloquialism_type: detectColloquialismType(row.phrases),
     // 'xiehouyu' | 'proverb' | 'idiom'
   }
   ```

## ç¤ºä¾‹ 5ï¼šå»£å·æ–¹è¨€è©å…¸

å‚è€ƒ `gz-dialect.js`ï¼Œå®ƒå±•ç¤ºäº†å¦‚ä½•å¤„ç†ï¼š

### CSV æ ¼å¼ç‰¹ç‚¹

å»£å·æ–¹è¨€è©å…¸æ˜¯ä¸€æœ¬ç»¼åˆæ€§æ–¹è¨€è¯å…¸ï¼ŒCSVæ ¼å¼åŒ…å«æ ¡å¯¹çŠ¶æ€å­—æ®µï¼š

```csv
index,headword,verified_headword,jyutping,verified_jyutping,definition,page,source_file,verification_status,verification_notes
1,å·´é–‰,,baa1' bai3,,â‘ å‰¯è©ã€‚è¡¨ç¨‹åº¦åŠ æ·±...,48,...
```

**å…³é”®ç‰¹æ€§**ï¼š
- `verified_headword` å’Œ `verified_jyutping`ï¼šå¦‚æœæœ‰å†…å®¹ï¼Œè¯´æ˜è¿˜åœ¨æ ¡å¯¹ä¸­
- æ•°æ®å¤„ç†æ—¶éœ€è¦è¿‡æ»¤æ‰æœªå®Œæˆæ ¡å¯¹çš„è¡Œ

### æ ¸å¿ƒåŠŸèƒ½å®ç°

1. **è¿‡æ»¤æœªæ ¡å¯¹æ•°æ®**
   
   ```javascript
   function shouldFilterRow(row) {
     // å¦‚æœ verified_headword æˆ– verified_jyutping æœ‰å†…å®¹ï¼Œè¯´æ˜è¿˜æ²¡æ ¡å¯¹å¥½
     return (row.verified_headword && row.verified_headword.trim() !== '') ||
            (row.verified_jyutping && row.verified_jyutping.trim() !== '')
   }
   
   export function transformRow(row) {
     if (shouldFilterRow(row)) {
       return null // è¿‡æ»¤æ‰
     }
     // ... ç»§ç»­å¤„ç†
   }
   ```

2. **è§£æå¤šä¹‰é¡¹å’Œä¾‹å¥**
   
   é‡Šä¹‰æ ¼å¼ï¼š`â‘ å‰¯è©ã€‚è¡¨ç¨‹åº¦ï¼šä¾‹å¥1ä¸¨ä¾‹å¥2<ç¿»è¯‘>`
   
   ```javascript
   function parseSenses(definition) {
     // æ£€æŸ¥æ˜¯å¦åŒ…å« â‘  â‘¡ â‘¢ ç­‰æ ‡è®°
     const sensePattern = /[â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©]/g
     const matches = [...text.matchAll(sensePattern)]
     
     if (matches.length === 0) {
       // æ²¡æœ‰å¤šä¹‰é¡¹æ ‡è®°ï¼Œæ•´ä¸ªä½œä¸ºä¸€ä¸ªä¹‰é¡¹
       return parseExamplesInDefinition(text)
     }
     
     // æœ‰å¤šä¹‰é¡¹æ ‡è®°ï¼Œåˆ†å‰²å¤„ç†
     // ...
   }
   ```

3. **æå–ä¾‹å¥å’Œç¿»è¯‘**
   
   æ”¯æŒå¤šç§æ ¼å¼ï¼š
   - `é‡Šä¹‰ï¼šä¾‹å¥1ä¸¨ä¾‹å¥2`
   - `é‡Šä¹‰<ç¿»è¯‘>`
   - `é‡Šä¹‰ â€– å¤‡æ³¨`
   
   ```javascript
   function parseExamplesInDefinition(text) {
     // å…ˆæå–å¤‡æ³¨ï¼ˆâ€– åé¢çš„å†…å®¹ï¼‰
     const noteMatch = text.match(/\s*â€–\s*(.+)$/)
     
     // æ£€æŸ¥æ˜¯å¦æœ‰ä¾‹å¥ï¼ˆç”¨å†’å·æˆ–ä¸¨åˆ†éš”ï¼‰
     const exampleSplit = mainText.split(/[:ï¼š]/)
     
     if (exampleSplit.length > 1) {
       sense.definition = exampleSplit[0].trim()
       // è§£æä¾‹å¥ï¼ˆå¯èƒ½ç”¨ä¸¨åˆ†éš”å¤šä¸ªä¾‹å¥ï¼‰
       const exampleParts = exampleText.split(/[ä¸¨ï½œ|]/)
       // ...
     }
   }
   ```

4. **å¿½ç•¥ç‰¹å®šå­—æ®µ**
   
   æŒ‰ç…§è¦æ±‚ï¼Œä»¥ä¸‹å­—æ®µä¸éœ€è¦å¤„ç†ï¼š
   
   ```javascript
   // âŒ ä¸å¤„ç†çš„å­—æ®µï¼š
   // - source_file
   // - verification_status
   // - verification_notes
   
   meta: {
     page: row.page || null,
     // æ³¨ï¼šsource_file, verification_status, verification_notes å­—æ®µå·²çœç•¥
   }
   ```

### ä½¿ç”¨è¯´æ˜

```bash
# è½¬æ¢å»£å·æ–¹è¨€è©å…¸æ•°æ®
node scripts/csv-to-json.js \
  --dict gz-dialect \
  --input data/processed/gz-dialect.csv

# æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯
# - ä¼šæ˜¾ç¤ºè¢«è¿‡æ»¤çš„è¡Œæ•°ï¼ˆæœªæ ¡å¯¹å®Œæˆçš„æ•°æ®ï¼‰
# - ä¼šæ˜¾ç¤ºè½¬æ¢æˆåŠŸçš„è¯æ¡æ•°
```

### æ•°æ®è´¨é‡è¯´æ˜

- âœ… å¤šä¹‰é¡¹æ ‡è®°æ¸…æ™°ï¼ˆâ‘ â‘¡â‘¢ï¼‰
- âœ… ä¾‹å¥å’Œç¿»è¯‘æ ¼å¼è§„èŒƒ
- âœ… å¤‡æ³¨ä¿¡æ¯å®Œæ•´ï¼ˆâ€– æ ‡è®°ï¼‰
- âš ï¸ éƒ¨åˆ†æ•°æ®ä»åœ¨æ ¡å¯¹ä¸­ï¼ˆä¼šè¢«è‡ªåŠ¨è¿‡æ»¤ï¼‰
- âš ï¸ é¡µç æ ¼å¼ä¸ºæ•°å­—

### è¿”å›æ ¼å¼

```javascript
// transformAll è¿”å›åŒ…å«è¿‡æ»¤ç»Ÿè®¡çš„å¯¹è±¡
{
  entries: [...],        // æˆåŠŸè½¬æ¢çš„è¯æ¡
  errors: [...],         // é”™è¯¯åˆ—è¡¨
  filteredCount: 123     // è¢«è¿‡æ»¤çš„è¡Œæ•°ï¼ˆæœªæ ¡å¯¹å®Œæˆï¼‰
}
```

### æ³¨æ„äº‹é¡¹

âš ï¸ **é‡è¦**ï¼š
- æœ‰ `verified_headword` æˆ– `verified_jyutping` çš„è¡Œä¼šè¢«è‡ªåŠ¨è¿‡æ»¤
- è¿™äº›å­—æ®µæœ‰å†…å®¹è¯´æ˜æ•°æ®è¿˜åœ¨æ ¡å¯¹ä¸­ï¼Œæš‚ä¸çº³å…¥æœ€ç»ˆè¯å…¸
- `source_file`ã€`verification_status`ã€`verification_notes` å­—æ®µä¸å¤„ç†
- è½¬æ¢å®Œæˆåä¼šæ˜¾ç¤ºè¿‡æ»¤æ‰çš„è¡Œæ•°

### è¯å…¸ä¿¡æ¯

```javascript
export const DICTIONARY_INFO = {
  id: 'gz-dialect',
  name: 'å»£å·æ–¹è¨€è©å…¸',
  author: 'ç™½å®›å¦‚',
  publisher: 'æ±Ÿè‹æ•™è‚²å‡ºç‰ˆç¤¾',
  year: 1998,
  description: 'æ”¶å½•å¹¿å·è¯è¯æ±‡ï¼ŒåŒ…å«é‡Šä¹‰ã€è¯»éŸ³ã€ç”¨ä¾‹ç­‰'
}
```

## ç¤ºä¾‹ 6ï¼šç²µèªè¾­æº

å‚è€ƒ `gz-word-origins.js`ï¼Œå®ƒå±•ç¤ºäº†å¦‚ä½•å¤„ç†ï¼š

### CSV æ ¼å¼ç‰¹ç‚¹

ç²µèªè¾­æºè¯å…¸çš„ç‰¹ç‚¹æ˜¯è®°å½•è¯è¯­çš„æ¥æºå’Œæ¼”å˜ï¼ŒCSVæ ¼å¼ä¸­åŒä¸€è¯æ¡åŒ…å«å¤šè¡Œï¼š

```csv
page,index,verified,entry,gwongping,jyutping,content,proofreaders_note
55_1,0,1,ä¸€èº«èŸ»,yed1 sen1 ngei5,jat1 san1 ngai5,å½¢å®¹æ‹›æƒ¹äº†ä¸å°‘éº»ç…©ã€‚ï¼ˆé¥’ç§‰æ‰ç­‰ï¼š2020ï¼š478ï¼‰,
55_1,0,1,,,,ã€æºã€‘åè™•å³æ‰€å§ï¼Œå§è™•å³æ‰€åã€‚ä¸‰æ—¥è¸åœ¨æ®¼ï¼Œï½æ–¼ç£¨ã€‚ï¼ˆæ¸…Â·ä½•ç´¹åŸºã€Šæ±æ´²è‰å ‚è©©éˆ”ã€‹å·äºŒåå››è‘‰åäºŒï¼Œæ¸…åŒæ²»å…­è‡³å…«å¹´é•·æ²™ç„¡åœ’åˆ»æœ¬ï¼‰,
```

- ç¬¬ä¸€è¡ŒåŒ…å«è¯æ¡åç§°ã€æ‹¼éŸ³å’Œé‡Šä¹‰
- åç»­è¡Œï¼ˆentryå’Œjyutpingä¸ºç©ºï¼‰åŒ…å«è¯æºå¼•ç”¨ã€æºã€‘å’ŒæŒ‰è¯­ã€æ¡ˆã€‘

### æ ¸å¿ƒåŠŸèƒ½å®ç°

1. **æŒ‰ page+index åˆ†ç»„**
   
   åŒä¸€è¯æ¡çš„å¤šè¡Œæ•°æ®éœ€è¦å…ˆåˆ†ç»„å†å¤„ç†ï¼š
   
   ```javascript
   function groupByEntry(rows) {
     const grouped = new Map()
     
     rows.forEach(row => {
       const key = `${row.page}_${row.index}`
       if (!grouped.has(key)) {
         grouped.set(key, [])
       }
       grouped.get(key).push(row)
     })
     
     return grouped
   }
   ```

2. **è§£æ content å­—æ®µ**
   
   content å­—æ®µå¯èƒ½åŒ…å«é‡Šä¹‰ã€è¯æºå¼•ç”¨æˆ–æŒ‰è¯­ï¼š
   
   ```javascript
   function parseContent(content) {
     if (content.startsWith('ã€æºã€‘')) {
       // è¯æºå¼•ç”¨è¡Œ
       const etymologyText = content.replace(/^ã€æºã€‘/, '').trim()
       return {
         definition: '',
         etymology: [etymologyText],
         commentary: null
       }
     } else if (content.startsWith('æ¡ˆï¼š')) {
       // æŒ‰è¯­/è¯´æ˜è¡Œ
       const commentary = content.replace(/^æ¡ˆï¼š/, '').trim()
       return {
         definition: '',
         etymology: [],
         commentary: commentary
       }
     } else {
       // é‡Šä¹‰è¡Œ
       return {
         definition: content,
         etymology: [],
         commentary: null
       }
     }
   }
   ```

3. **è§£æå¤šä¹‰é¡¹æ ‡è®°**ï¼ˆâ‘ â‘¡â‘¢æ ¼å¼ï¼‰
   
   ```javascript
   function parseSenses(definition) {
     const sensePattern = /[â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©]/g
     const matches = [...definition.matchAll(sensePattern)]
     
     if (matches.length === 0) {
       return [{ definition: definition.trim(), examples: [] }]
     }
     
     const senses = []
     for (let i = 0; i < matches.length; i++) {
       const start = matches[i].index + 1
       const end = i < matches.length - 1 ? matches[i + 1].index : definition.length
       const senseText = definition.substring(start, end).trim()
       
       if (senseText) {
         senses.push({ definition: senseText, examples: [] })
       }
     }
     
     return senses
   }
   ```

4. **å¤„ç†åŒå½¢å¼‚ä¹‰è¯**ï¼ˆå¦‚"ä¸€å‘³1"ã€"ä¸€å‘³2"ï¼‰
   
   ```javascript
   function parseEntryName(entry) {
     // æ£€æŸ¥æ˜¯å¦æœ‰æ•°å­—åç¼€
     const match = entry.match(/^(.+?)(\d+)$/)
     if (match) {
       return {
         baseEntry: match[1].trim(),
         variantNumber: parseInt(match[2])
       }
     }
     
     return {
       baseEntry: entry.trim(),
       variantNumber: null
     }
   }
   
   // åœ¨ aggregateEntries ä¸­èšåˆåŒå½¢å¼‚ä¹‰è¯
   export function aggregateEntries(entries) {
     // æŒ‰è¯å¤´å’Œè¯»éŸ³åˆ†ç»„
     const grouped = new Map()
     entries.forEach(entry => {
       const key = `${entry.headword.normalized}_${entry.phonetic.jyutping[0]}`
       // ... èšåˆé€»è¾‘
     })
   }
   ```

5. **çµæ´»çš„å¿…å¡«å­—æ®µéªŒè¯**
   
   å› ä¸ºåç»­è¡Œçš„entryå’Œjyutpingä¸ºç©ºï¼Œæ‰€ä»¥åªéªŒè¯æ ¸å¿ƒå­—æ®µï¼š
   
   ```javascript
   export const REQUIRED_FIELDS = ['page', 'index', 'content']
   // entry å’Œ jyutping ä¸æ˜¯å¿…å¡«ï¼Œå…è®¸è¯æºå¼•ç”¨è¡Œä¸ºç©º
   ```

### ä½¿ç”¨è¯´æ˜

```bash
# è½¬æ¢ç²µèªè¾­æºæ•°æ®
node scripts/csv-to-json.js \
  --dict gz-word-origins \
  --input data/processed/gz-word-origins.csv

# ç”Ÿæˆçš„è¯æ¡åŒ…å«ä¸°å¯Œçš„è¯æºä¿¡æ¯
```

### æ•°æ®ç‰¹ç‚¹

```javascript
// å…¸å‹è¯æ¡ç»“æ„
{
  "headword": { "display": "ä¸€æ–¼" },
  "phonetic": {
    "original": "yed1 yÃ¼1",
    "jyutping": ["jat1 jyu1"]
  },
  "senses": [
    { "definition": "å …æ±ºã€‚" },
    { "definition": "ä¸€å®šè¦ï¼›æ€éº¼ä¹Ÿâ€¦â€¦ã€‚" },
    { "definition": "å°±â€¦â€¦ã€‚ï¼ˆé¥’ç§‰æ‰ç­‰ï¼š2020ï¼š479ï¼‰" }
  ],
  "meta": {
    "page": "55_1",
    "verified": true,
    "etymology": [
      "è³¢è€…æˆ–å‡ºæˆ–è™•ï¼Œï½çˆ²é“è€Œå·²ï¼Œè±ˆæ›°å¾’åå“‰ï¼Ÿï¼ˆå®‹Â·ç¨‹çŒã€Šæ´ºæ°´é›†ã€‹å·ä¹è‘‰åäºŒï¼Œæ¸…æ–‡æ·µé–£å››åº«å…¨æ›¸æœ¬ï¼‰ï½œ..."
    ],
    "commentary": "å¤æ¼¢èªçš„"ä¸€æ–¼"ï¼Œè¡¨"åªåœ¨æ–¼"çš„æ„ç¾©ï¼Œç²µèªå¼•ç”³çˆ²"å …æ±º"ã€"å‹™å¿…"ç­‰æ„ç¾©ã€‚",
    "gwongping": "yed1 yÃ¼1"
  }
}
```

### æ³¨æ„äº‹é¡¹

âš ï¸ **é‡è¦**ï¼š
- CSVä¸­åŒä¸€è¯æ¡åŒ…å«å¤šè¡Œï¼Œéœ€è¦æ­£ç¡®åˆ†ç»„
- è¯æºå¼•ç”¨ï¼ˆã€æºã€‘ï¼‰å’ŒæŒ‰è¯­ï¼ˆæ¡ˆï¼šï¼‰åœ¨å•ç‹¬çš„è¡Œä¸­
- åŒå½¢å¼‚ä¹‰è¯ï¼ˆå¦‚"ä¸€å‘³1"ã€"ä¸€å‘³2"ï¼‰ä¼šè¢«è‡ªåŠ¨èšåˆ
- ä¿ç•™äº†å¹¿å·è¯æ‹¼éŸ³æ–¹æ¡ˆ(gwongping)ç”¨äºç ”ç©¶å¯¹æ¯”

### ç»Ÿè®¡æ•°æ®

- æ€»è¯æ¡æ•°ï¼šçº¦ 3,950 æ¡
- åŒ…å«è¯æºçš„è¯æ¡ï¼š99.9%ï¼ˆå‡ ä¹æ‰€æœ‰è¯æ¡éƒ½æœ‰è¯æºå¼•ç”¨ï¼‰
- åŒ…å«æŒ‰è¯­çš„è¯æ¡ï¼šçº¦ 487 æ¡ï¼ˆ12%ï¼‰
- å¤šä¹‰é¡¹è¯æ¡ï¼šçº¦ 619 æ¡ï¼ˆ16%ï¼‰

---

## å¸¸è§é—®é¢˜

### Q: å¦‚ä½•å¤„ç†ä¾‹å¥ä¸­çš„ç¿»è¯‘ï¼Ÿ

```javascript
import { parseExamples } from '../utils/text-processor.js'

// è‡ªåŠ¨è§£æ "ä¾‹å¥ã€‚ï¼ˆç¿»è¯‘ã€‚ï¼‰" æ ¼å¼
const { definition, examples } = parseExamples(row.meanings)
```

### Q: å¦‚ä½•å¤„ç†å¤šéŸ³å­—ï¼Ÿ

å¦‚æœä¸€ä¸ªå­—æœ‰å¤šä¸ªè¯»éŸ³ï¼Œåˆ†è¡Œè®°å½•ï¼Œä½¿ç”¨ç›¸åŒçš„ `id`ï¼Œåœ¨èšåˆæ—¶ä¼šè‡ªåŠ¨åˆå¹¶ã€‚

### Q: å¦‚ä½•å¤„ç†å‚è§å¼•ç”¨ï¼Ÿ

åœ¨ CSV ä¸­æ·»åŠ  `ref_word` æˆ– `ref_section` å­—æ®µï¼š

```javascript
if (row.ref_word) {
  entry.refs = [{
    type: 'word',
    target: row.ref_word
  }]
}
```

### Q: å¦‚ä½•å¤„ç†å¼€å¤©çª—å­— â–¡ï¼Ÿ

`cleanHeadword()` ä¼šè‡ªåŠ¨æ£€æµ‹ï¼š

```javascript
const headwordInfo = cleanHeadword('â–¡å˜¢')
// headwordInfo.isPlaceholder === true
```

---

## å¯ç”¨çš„å·¥å…·å‡½æ•°

ä½äº `scripts/utils/text-processor.js`:

| å‡½æ•° | ç”¨é€” |
|------|------|
| `removeTones(jyutping)` | å»é™¤ç²¤æ‹¼å£°è°ƒ |
| `generateKeywords(entry)` | ç”Ÿæˆæœç´¢å…³é”®è¯ï¼ˆä¸å«ç®€ç¹ä½“ï¼‰ |
| `extractVariants(text)` | æå–å¼‚å½¢è¯ |
| `cleanHeadword(word)` | æ¸…ç†è¯å¤´æ ‡è®° |
| `parseExamples(meanings)` | è§£æä¾‹å¥ |
| `parseNote(note)` | è§£æå¤‡æ³¨ |

**æ³¨æ„**ï¼šç®€ç¹ä½“è½¬æ¢å·²ç§»è‡³è¿è¡Œæ—¶å¤„ç†ï¼ˆ`composables/useChineseConverter.ts`ï¼‰ï¼Œæ— éœ€åœ¨é€‚é…å™¨ä¸­å¤„ç†ã€‚æ‰€æœ‰è¯å…¸çš„æ•°æ®åªéœ€ä¿æŒåŸå§‹å½¢å¼å³å¯ï¼Œæœç´¢æ—¶ä¼šè‡ªåŠ¨æ”¯æŒç®€ç¹ä½“ã€‚

---

## æµ‹è¯•æ¸…å•

å¼€å‘å®Œé€‚é…å™¨åï¼Œæ£€æŸ¥ï¼š

- [ ] æ‰€æœ‰å¿…å¡«å­—æ®µæ­£ç¡®æ˜ å°„
- [ ] ç²¤æ‹¼æ ¼å¼æ­£ç¡®ï¼ˆç©ºæ ¼åˆ†éš”éŸ³èŠ‚ï¼‰
- [ ] æœç´¢å…³é”®è¯å®Œæ•´ï¼ˆæ— éœ€åŒ…å«ç®€ç¹ä½“ï¼‰
- [ ] ç‰¹æ®Šå­—ç¬¦å¤„ç†æ­£ç¡®
- [ ] åˆ†ç±»/å¤‡æ³¨ç­‰å…ƒæ•°æ®æ­£ç¡®
- [ ] è¿è¡Œ `validate.js` æ— é”™è¯¯
- [ ] è¿è¡Œ `csv-to-json.js` æˆåŠŸ
- [ ] ç”Ÿæˆçš„ JSON æ ¼å¼æ­£ç¡®

---

## è´¡çŒ®ä½ çš„é€‚é…å™¨

å¦‚æœä½ ä¸ºæ–°è¯å…¸å¼€å‘äº†é€‚é…å™¨ï¼Œæ¬¢è¿æäº¤ PRï¼š

1. å°†é€‚é…å™¨æ–‡ä»¶æ”¾å…¥ `scripts/adapters/`
2. æ›´æ–° `scripts/csv-to-json.js` æ³¨å†Œé€‚é…å™¨
3. æä¾›ç¤ºä¾‹ CSV æ•°æ®ï¼ˆè‡³å°‘ 10 æ¡ï¼‰
4. åœ¨ PR ä¸­è¯´æ˜è¯å…¸çš„ç‰¹æ®Šä¹‹å¤„

---

## éœ€è¦å¸®åŠ©ï¼Ÿ

- æŸ¥çœ‹ç°æœ‰é€‚é…å™¨æºç 
- é˜…è¯» [DATA_SCHEMA.md](../../docs/DATA_SCHEMA.md)
- åœ¨ [GitHub Discussions](https://github.com/jyutjyucom/jyutjyu/discussions) æé—®

---

## å¤§å‹è¯å…¸ä¼˜åŒ–ï¼šåˆ†ç‰‡åŠ è½½

å¯¹äºè¯æ¡æ•°é‡è¶…è¿‡ 10 ä¸‡çš„å¤§å‹è¯å…¸ï¼ˆå¦‚ Wiktionaryï¼‰ï¼Œç”Ÿæˆçš„ JSON æ–‡ä»¶å¯èƒ½è¶…è¿‡ 100MBï¼Œå¯¼è‡´ï¼š
- âŒ é¦–æ¬¡åŠ è½½æ…¢ï¼ˆéœ€è¦ä¸‹è½½æ•´ä¸ªå¤§æ–‡ä»¶ï¼‰
- âŒ å†…å­˜å ç”¨å¤§ï¼ˆæµè§ˆå™¨éœ€è¦è§£ææ‰€æœ‰æ•°æ®ï¼‰
- âŒ æœç´¢æ€§èƒ½å·®ï¼ˆéœ€è¦éå†å¤§é‡æ•°æ®ï¼‰

**è§£å†³æ–¹æ¡ˆ**ï¼šä½¿ç”¨åˆ†ç‰‡åŠ è½½ï¼ˆChunked Loadingï¼‰

### å·¥ä½œåŸç†

1. **æ•°æ®åˆ†ç‰‡**ï¼šæŒ‰ç²¤æ‹¼é¦–å­—æ¯å°†è¯å…¸åˆ†æˆ 20-30 ä¸ªå°æ–‡ä»¶
2. **æŒ‰éœ€åŠ è½½**ï¼šæœç´¢æ—¶åªåŠ è½½ç›¸å…³çš„ 1-2 ä¸ªåˆ†ç‰‡ï¼ˆ2-8MBï¼‰
3. **æ•°æ®ä¼˜åŒ–**ï¼šç§»é™¤å†—ä½™å­—æ®µï¼Œå‡å°‘æ–‡ä»¶å¤§å° 40-50%
4. **å®¢æˆ·ç«¯ç¼“å­˜**ï¼šå·²åŠ è½½çš„åˆ†ç‰‡ä¼šè¢«ç¼“å­˜ï¼Œé¿å…é‡å¤è¯·æ±‚

### æ•ˆæœå¯¹æ¯”

| æŒ‡æ ‡ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æ”¹å–„ |
|------|--------|--------|------|
| æ–‡ä»¶æ€»å¤§å° | 135 MB | 66 MB | â†“ 51% |
| é¦–æ¬¡åŠ è½½ | ä¸‹è½½ 135MB | 0 MB | â†“ 100% |
| æœç´¢"book" | å·²åŠ è½½å…¨éƒ¨ | ä¸‹è½½ 4MB | â†“ 97% |
| å†…å­˜å ç”¨ | ~200 MB | ~30 MB | â†“ 85% |

### ä½¿ç”¨æ–¹æ³•

#### Step 1: åœ¨é€‚é…å™¨ä¸­å¯ç”¨åˆ†ç‰‡

åœ¨é€‚é…å™¨çš„ `DICTIONARY_INFO` ä¸­æ·»åŠ ï¼š

```javascript
export const DICTIONARY_INFO = {
  id: 'my-large-dict',
  name: 'æˆ‘çš„å¤§å‹è¯å…¸',
  // ... å…¶ä»–å­—æ®µ
  
  // å¯ç”¨åˆ†ç‰‡ï¼ˆè¯æ¡æ•° > 50000 å»ºè®®å¯ç”¨ï¼‰
  enable_chunking: true,
  chunk_output_dir: 'my-large-dict' // åˆ†ç‰‡è¾“å‡ºç›®å½•å
}
```

#### Step 2: åœ¨é€‚é…å™¨ä¸­æ·»åŠ åˆ†ç‰‡åå¤„ç†

åœ¨é€‚é…å™¨æ–‡ä»¶æœ«å°¾æ·»åŠ ï¼š

```javascript
/**
 * åå¤„ç†ï¼šè‡ªåŠ¨åˆ†ç‰‡å¤§å‹è¯å…¸
 */
export async function postProcess(entries, outputPath) {
  if (!DICTIONARY_INFO.enable_chunking) {
    return entries // ä¸åˆ†ç‰‡ï¼Œç›´æ¥è¿”å›
  }
  
  console.log('ğŸ”§ æ£€æµ‹åˆ°å¤§å‹è¯å…¸ï¼Œå¯ç”¨è‡ªåŠ¨åˆ†ç‰‡...')
  
  // åŠ¨æ€å¯¼å…¥åˆ†ç‰‡æ¨¡å—
  const { splitDictionary } = await import('../split-dictionary.cjs')
  
  // ç¡®å®šè¾“å‡ºç›®å½•
  const outputDir = outputPath.replace(/\.json$/, '')
  const chunkDir = DICTIONARY_INFO.chunk_output_dir || 
                   DICTIONARY_INFO.id.replace(/-cantonese$/, '')
  
  const finalOutputDir = outputDir + '/' + chunkDir
  
  // æ‰§è¡Œåˆ†ç‰‡
  await splitDictionary(outputPath, finalOutputDir)
  
  console.log('âœ… åˆ†ç‰‡å®Œæˆ')
  return entries
}
```

#### Step 3: æ›´æ–°å‰ç«¯é…ç½®

åœ¨ `public/dictionaries/index.json` ä¸­æ ‡è®°ä¸ºåˆ†ç‰‡è¯å…¸ï¼š

```json
{
  "id": "my-large-dict",
  "name": "æˆ‘çš„å¤§å‹è¯å…¸",
  "file": "my-large-dict.json",
  "entries_count": 100000,
  "chunked": true,
  "chunk_dir": "my-large-dict",
  ...
}
```

å‰ç«¯ä¼šè‡ªåŠ¨è¯†åˆ« `chunked: true` å¹¶æŒ‰éœ€åŠ è½½åˆ†ç‰‡ã€‚

### åˆ†ç‰‡ç­–ç•¥

**æŒ‰æ‹¼éŸ³é¦–å­—æ¯åˆ†ç‰‡**ï¼š
- a-z: 26ä¸ªåŸºç¡€åˆ†ç‰‡
- other: ç‰¹æ®Šå­—ç¬¦åˆ†ç‰‡

**æ•°æ®ä¼˜åŒ–**ï¼š
```javascript
// ä¿ç•™å­—æ®µï¼ˆæœç´¢å¿…éœ€ï¼‰
{
  id, source_book, headword, phonetic, 
  entry_type, senses, keywords
}

// ç²¾ç®€ metaï¼ˆåªä¿ç•™æ ¸å¿ƒï¼‰
meta: {
  pos, register, variants
}

// ç§»é™¤å­—æ®µï¼ˆéæœç´¢å¿…éœ€ï¼‰
// âŒ meta.etymology
// âŒ meta.ipa  
// âŒ meta.derived
// âŒ meta.related
// âŒ created_at
```

### åˆ†ç‰‡æ–‡ä»¶ç»“æ„

```
public/dictionaries/
â”œâ”€â”€ my-large-dict.json          # åŸå§‹å®Œæ•´æ–‡ä»¶ï¼ˆå¤‡ä»½ï¼‰
â””â”€â”€ my-large-dict/              # åˆ†ç‰‡ç›®å½•
    â”œâ”€â”€ manifest.json           # åˆ†ç‰‡ç´¢å¼•
    â”œâ”€â”€ a.json                  # é¦–å­—æ¯ a
    â”œâ”€â”€ b.json                  # é¦–å­—æ¯ b
    â”œâ”€â”€ c.json                  # é¦–å­—æ¯ c
    â””â”€â”€ ...                     # å…¶ä»–åˆ†ç‰‡
```

### ç¤ºä¾‹ï¼šWiktionary åˆ†ç‰‡é…ç½®

å‚è€ƒ `wiktionary-cantonese.js` çš„å®Œæ•´å®ç°ï¼š

```javascript
export const DICTIONARY_INFO = {
  id: 'wiktionary-cantonese',
  name: 'Wiktionaryç²¤è¯­è¯æ¡',
  // ... å…¶ä»–å­—æ®µ
  enable_chunking: true,
  chunk_output_dir: 'wiktionary'
}

// èšåˆåè‡ªåŠ¨åˆ†ç‰‡
export async function postProcess(entries, outputPath) {
  if (!DICTIONARY_INFO.enable_chunking) return entries
  
  const path = await import('path')
  const outputDir = path.dirname(outputPath)
  const chunkDir = path.join(
    outputDir, 
    DICTIONARY_INFO.chunk_output_dir
  )
  
  // å¯¼å…¥åˆ†ç‰‡æ¨¡å—
  const splitModule = await import('../split-dictionary.cjs')
  
  // æ‰§è¡Œåˆ†ç‰‡
  await splitModule.splitDictionary(outputPath, chunkDir)
  
  return entries
}
```

### æ³¨æ„äº‹é¡¹

1. **ä¿ç•™åŸå§‹æ–‡ä»¶**ï¼šåˆ†ç‰‡åä»ä¿ç•™å®Œæ•´ JSON æ–‡ä»¶ä½œä¸ºå¤‡ä»½
2. **ç´¢å¼•åŒæ­¥**ï¼šç¡®ä¿ `index.json` ä¸­æ­£ç¡®é…ç½® `chunked` å’Œ `chunk_dir`
3. **ç¼“å­˜ç­–ç•¥**ï¼šå»ºè®®è®¾ç½® HTTP ç¼“å­˜å¤´ï¼ˆmax-age=86400ï¼‰
4. **é™æ€éƒ¨ç½²**ï¼šåˆ†ç‰‡æ–¹æ¡ˆå®Œå…¨å…¼å®¹é™æ€éƒ¨ç½²ï¼ˆNetlify/Vercelï¼‰

### ä½•æ—¶ä½¿ç”¨åˆ†ç‰‡

âœ… **å»ºè®®å¯ç”¨åˆ†ç‰‡**ï¼š
- è¯æ¡æ•° > 50,000
- JSON æ–‡ä»¶ > 30 MB
- æœç´¢æ€§èƒ½æœ‰æ˜æ˜¾å»¶è¿Ÿ

âŒ **ä¸å»ºè®®åˆ†ç‰‡**ï¼š
- è¯æ¡æ•° < 20,000
- JSON æ–‡ä»¶ < 10 MB
- æ–‡ä»¶å·²ç»å¾ˆå°ä¸”åŠ è½½å¿«é€Ÿ

### æ€§èƒ½ç›‘æ§

å¼€å‘æ—¶å¯ä»¥åœ¨æµè§ˆå™¨æ§åˆ¶å°æŸ¥çœ‹åˆ†ç‰‡åŠ è½½æƒ…å†µï¼š

```javascript
// ä¼šçœ‹åˆ°ç±»ä¼¼æ—¥å¿—ï¼š
// âœ… å·²åŠ è½½åˆ†ç‰‡: wiktionary/b.json (6154 æ¡)
// â­ï¸ è·³è¿‡åˆ†ç‰‡è¯å…¸: wiktionary-cantonese (æŒ‰éœ€åŠ è½½)
```

---

