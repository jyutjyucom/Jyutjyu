#!/usr/bin/env node

/**
 * JSONL è½¬ JSON è„šæœ¬
 * ä¸“é—¨ç”¨äºå¤„ç† Wiktionary ç­‰ JSONL æ ¼å¼çš„è¯å…¸æ•°æ®
 * 
 * ç”¨æ³•:
 *   node scripts/jsonl-to-json.js --dict wiktionary-cantonese --input data/processed/wiktionary_cantonese_entries.jsonl
 *   
 * æˆ–ä½¿ç”¨ npm è„šæœ¬:
 *   pnpm build:wiktionary
 */

import fs from 'fs'
import path from 'path'
import { parseArgs } from 'node:util'
import readline from 'readline'

// åŠ¨æ€å¯¼å…¥é€‚é…å™¨
const ADAPTERS = {
  'wiktionary-cantonese': () => import('./adapters/wiktionary-cantonese.js'),
  // æœªæ¥å¯ä»¥æ·»åŠ æ›´å¤šJSONLæ ¼å¼çš„è¯å…¸
}

/**
 * è¯»å– JSONL æ–‡ä»¶
 * @param {string} filePath - æ–‡ä»¶è·¯å¾„
 * @param {number} maxLines - æœ€å¤§è¯»å–è¡Œæ•°ï¼ˆç”¨äºæµ‹è¯•ï¼‰
 * @returns {Promise<Array>} è§£æåçš„å¯¹è±¡æ•°ç»„
 */
async function parseJSONL(filePath, maxLines = null) {
  const entries = []
  let lineCount = 0
  
  const fileStream = fs.createReadStream(filePath)
  const rl = readline.createInterface({
    input: fileStream,
    crlfDelay: Infinity
  })
  
  console.log(`â³ å¼€å§‹è¯»å– JSONL æ–‡ä»¶: ${filePath}`)
  
  for await (const line of rl) {
    lineCount++
    
    // æ˜¾ç¤ºè¿›åº¦
    if (lineCount % 10000 === 0) {
      process.stdout.write(`\r   å·²è¯»å– ${lineCount} è¡Œ...`)
    }
    
    // è·³è¿‡ç©ºè¡Œ
    if (!line.trim()) continue
    
    try {
      const entry = JSON.parse(line)
      entries.push(entry)
      
      // å¦‚æœè®¾ç½®äº†æœ€å¤§è¡Œæ•°é™åˆ¶ï¼ˆç”¨äºæµ‹è¯•ï¼‰
      if (maxLines && entries.length >= maxLines) {
        console.log(`\n   å·²è¾¾åˆ°æœ€å¤§è¡Œæ•°é™åˆ¶: ${maxLines}`)
        break
      }
    } catch (error) {
      console.warn(`\nâš ï¸  ç¬¬ ${lineCount} è¡Œè§£æå¤±è´¥: ${error.message}`)
    }
  }
  
  process.stdout.write('\r                                    \r')
  console.log(`âœ… è¯»å–å®Œæˆ: ${lineCount} è¡Œï¼ŒæˆåŠŸè§£æ ${entries.length} ä¸ªè¯æ¡`)
  
  return entries
}

/**
 * ä¸»å‡½æ•°
 */
async function main() {
  // è§£æå‘½ä»¤è¡Œå‚æ•°
  const { values } = parseArgs({
    options: {
      dict: {
        type: 'string',
        short: 'd'
      },
      input: {
        type: 'string',
        short: 'i'
      },
      output: {
        type: 'string',
        short: 'o'
      },
      aggregate: {
        type: 'boolean',
        default: true
      },
      limit: {
        type: 'string', // æµ‹è¯•ç”¨ï¼šé™åˆ¶è¯»å–è¡Œæ•°
        short: 'l'
      },
      help: {
        type: 'boolean',
        short: 'h'
      }
    }
  })

  if (values.help) {
    printHelp()
    process.exit(0)
  }

  // éªŒè¯å‚æ•°
  if (!values.dict || !values.input) {
    console.error('âŒ é”™è¯¯: ç¼ºå°‘å¿…éœ€å‚æ•°')
    printHelp()
    process.exit(1)
  }

  // æ£€æŸ¥é€‚é…å™¨æ˜¯å¦å­˜åœ¨
  if (!ADAPTERS[values.dict]) {
    console.error(`âŒ é”™è¯¯: æœªæ‰¾åˆ°è¯å…¸é€‚é…å™¨ "${values.dict}"`)
    console.log('\nå¯ç”¨çš„é€‚é…å™¨:')
    Object.keys(ADAPTERS).forEach(key => {
      console.log(`  - ${key}`)
    })
    process.exit(1)
  }

  // æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
  if (!fs.existsSync(values.input)) {
    console.error(`âŒ é”™è¯¯: è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: ${values.input}`)
    process.exit(1)
  }

  console.log('ğŸš€ å¼€å§‹è½¬æ¢...\n')
  console.log(`ğŸ“– è¯å…¸: ${values.dict}`)
  console.log(`ğŸ“„ è¾“å…¥: ${values.input}`)
  
  if (values.limit) {
    console.log(`âš ï¸  æµ‹è¯•æ¨¡å¼: é™åˆ¶è¯»å– ${values.limit} æ¡`)
  }

  try {
    // 1. åŠ è½½é€‚é…å™¨
    console.log('\nâ³ åŠ è½½é€‚é…å™¨...')
    const adapter = await ADAPTERS[values.dict]()
    console.log(`âœ… é€‚é…å™¨åŠ è½½æˆåŠŸ: ${adapter.DICTIONARY_INFO.name}`)

    // 2. è¯»å– JSONL
    console.log('\nâ³ è¯»å– JSONL æ–‡ä»¶...')
    const maxLines = values.limit ? parseInt(values.limit) : null
    const rawData = await parseJSONL(values.input, maxLines)
    
    if (rawData.length === 0) {
      console.error('âŒ é”™è¯¯: æ²¡æœ‰è¯»å–åˆ°ä»»ä½•æœ‰æ•ˆæ•°æ®')
      process.exit(1)
    }

    // 3. è½¬æ¢æ•°æ®
    console.log('\nâ³ è½¬æ¢æ•°æ®æ ¼å¼...')
    const startTime = Date.now()
    const { entries, errors, skipped } = adapter.transformAll(rawData)
    const duration = ((Date.now() - startTime) / 1000).toFixed(2)
    
    if (errors.length > 0) {
      console.warn(`\nâš ï¸  è½¬æ¢è¿‡ç¨‹ä¸­å‘ç° ${errors.length} ä¸ªé”™è¯¯:`)
      errors.slice(0, 5).forEach(err => {
        console.warn(`   è¯æ¡ ${err.index} (${err.word}): ${err.error}`)
      })
      if (errors.length > 5) {
        console.warn(`   ... è¿˜æœ‰ ${errors.length - 5} ä¸ªé”™è¯¯`)
      }
    }

    console.log(`âœ… æˆåŠŸè½¬æ¢ ${entries.length} ä¸ªç²¤è¯­è¯æ¡ (è€—æ—¶ ${duration}ç§’)`)
    console.log(`â„¹ï¸  è·³è¿‡ ${skipped} ä¸ªéç²¤è¯­è¯æ¡`)

    if (entries.length === 0) {
      console.error('âŒ é”™è¯¯: æ²¡æœ‰æˆåŠŸè½¬æ¢ä»»ä½•è¯æ¡')
      process.exit(1)
    }

    // 4. èšåˆé‡å¤è¯æ¡ï¼ˆå¯é€‰ï¼‰
    let finalEntries = entries
    if (values.aggregate && adapter.aggregateEntries) {
      console.log('\nâ³ èšåˆé‡å¤è¯æ¡...')
      const before = entries.length
      finalEntries = adapter.aggregateEntries(entries)
      console.log(`âœ… èšåˆå®Œæˆ: ${before} â†’ ${finalEntries.length} ä¸ªè¯æ¡`)
    }

    // 5. ç”Ÿæˆè¾“å‡ºè·¯å¾„
    const outputPath = values.output || 
      path.join('public', 'dictionaries', `${values.dict}.json`)
    
    const outputDir = path.dirname(outputPath)
    if (!fs.existsSync(outputDir)) {
      fs.mkdirSync(outputDir, { recursive: true })
    }

    // 6. å†™å…¥ JSON
    console.log(`\nâ³ å†™å…¥ JSON æ–‡ä»¶: ${outputPath}`)
    fs.writeFileSync(
      outputPath,
      JSON.stringify(finalEntries, null, 2),
      'utf-8'
    )
    const fileSize = (fs.statSync(outputPath).size / 1024 / 1024).toFixed(2)
    console.log(`âœ… å†™å…¥æˆåŠŸ (${fileSize} MB)`)

    // 7. æ›´æ–°è¯å…¸ç´¢å¼•
    console.log('\nâ³ æ›´æ–°è¯å…¸ç´¢å¼•...')
    updateDictionaryIndex(adapter.DICTIONARY_INFO, finalEntries.length)
    console.log('âœ… ç´¢å¼•æ›´æ–°æˆåŠŸ')

    // 7.5. æ‰§è¡Œåå¤„ç†ï¼ˆå¦‚è‡ªåŠ¨åˆ†ç‰‡ï¼‰
    if (adapter.postProcess && typeof adapter.postProcess === 'function') {
      console.log('\nâ³ æ‰§è¡Œåå¤„ç†...')
      try {
        await adapter.postProcess(finalEntries, outputPath)
      } catch (error) {
        console.error('âš ï¸  åå¤„ç†å‡ºé”™:', error.message)
        console.log('âš ï¸  å°†ç»§ç»­å®Œæˆæ•°æ®ç”Ÿæˆæµç¨‹')
      }
    }

    // 8. è¾“å‡ºç»Ÿè®¡
    console.log('\n' + '='.repeat(50))
    console.log('ğŸ“Š è½¬æ¢ç»Ÿè®¡:')
    console.log('='.repeat(50))
    console.log(`æ€»è¯æ¡æ•°:      ${rawData.length}`)
    console.log(`è·³è¿‡è¯æ¡:      ${skipped}`)
    console.log(`è½¬æ¢é”™è¯¯:      ${errors.length}`)
    console.log(`æˆåŠŸè¯æ¡:      ${finalEntries.length}`)
    console.log(`è¾“å‡ºæ–‡ä»¶:      ${outputPath}`)
    console.log(`æ–‡ä»¶å¤§å°:      ${fileSize} MB`)
    console.log(`è½¬æ¢è€—æ—¶:      ${duration}ç§’`)
    console.log('='.repeat(50))

    console.log('\nâœ… è½¬æ¢å®Œæˆï¼\n')

  } catch (error) {
    console.error('\nâŒ è½¬æ¢å¤±è´¥:', error.message)
    console.error(error.stack)
    process.exit(1)
  }
}

/**
 * æ›´æ–°è¯å…¸ç´¢å¼•æ–‡ä»¶
 */
function updateDictionaryIndex(dictInfo, entryCount) {
  const indexPath = path.join('content', 'dictionaries', 'index.json')
  const publicIndexPath = path.join('public', 'dictionaries', 'index.json')
  
  let index = { dictionaries: [], last_updated: '', schema_version: '1.0.0' }
  
  // è¯»å–ç°æœ‰ç´¢å¼•
  if (fs.existsSync(indexPath)) {
    index = JSON.parse(fs.readFileSync(indexPath, 'utf-8'))
  }

  // æŸ¥æ‰¾æˆ–åˆ›å»ºè¯å…¸æ¡ç›®
  let dictEntry = index.dictionaries.find(d => d.id === dictInfo.id)
  
  if (!dictEntry) {
    dictEntry = {
      id: dictInfo.id,
      name: dictInfo.name,
      dialect: dictInfo.dialect.name,
      file: `${dictInfo.id}.json`
    }
    index.dictionaries.push(dictEntry)
  }

  // æ›´æ–°è¯æ¡æ•°å’Œå…ƒä¿¡æ¯
  dictEntry.entries_count = entryCount
  dictEntry.author = dictInfo.author
  dictEntry.publisher = dictInfo.publisher
  dictEntry.year = dictInfo.year
  dictEntry.source = dictInfo.source
  dictEntry.license = dictInfo.license
  dictEntry.license_url = dictInfo.license_url
  dictEntry.attribution = dictInfo.attribution
  dictEntry.usage_restriction = dictInfo.usage_restriction
  
  // åˆ†ç‰‡é…ç½®ï¼ˆå¦‚æœå¯ç”¨ï¼‰
  if (dictInfo.enable_chunking) {
    dictEntry.chunked = true
    dictEntry.chunk_dir = dictInfo.chunk_output_dir || dictInfo.id.replace(/-cantonese$/, '')
  }

  // æ›´æ–°æ—¶é—´æˆ³
  index.last_updated = new Date().toISOString()

  // å†™å…¥æ–‡ä»¶åˆ°ä¸¤ä¸ªä½ç½®
  const indexContent = JSON.stringify(index, null, 2)
  
  // ç¡®ä¿ç›®å½•å­˜åœ¨
  const contentDir = path.dirname(indexPath)
  const publicDir = path.dirname(publicIndexPath)
  if (!fs.existsSync(contentDir)) {
    fs.mkdirSync(contentDir, { recursive: true })
  }
  if (!fs.existsSync(publicDir)) {
    fs.mkdirSync(publicDir, { recursive: true })
  }
  
  fs.writeFileSync(indexPath, indexContent, 'utf-8')
  fs.writeFileSync(publicIndexPath, indexContent, 'utf-8')
  
  console.log(`âœ… ç´¢å¼•æ–‡ä»¶å·²åŒæ­¥åˆ° content/ å’Œ public/ ç›®å½•`)
}

/**
 * æ‰“å°å¸®åŠ©ä¿¡æ¯
 */
function printHelp() {
  console.log(`
JSONL è½¬ JSON å·¥å…·

ç”¨æ³•:
  node scripts/jsonl-to-json.js [é€‰é¡¹]

é€‰é¡¹:
  -d, --dict <name>      è¯å…¸é€‚é…å™¨åç§° (å¿…éœ€)
  -i, --input <path>     è¾“å…¥ JSONL æ–‡ä»¶è·¯å¾„ (å¿…éœ€)
  -o, --output <path>    è¾“å‡º JSON æ–‡ä»¶è·¯å¾„ (å¯é€‰)
  --aggregate            æ˜¯å¦èšåˆé‡å¤è¯æ¡ (é»˜è®¤: true)
  -l, --limit <number>   é™åˆ¶å¤„ç†çš„è¯æ¡æ•°ï¼ˆç”¨äºæµ‹è¯•ï¼‰
  -h, --help             æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯

å¯ç”¨çš„è¯å…¸é€‚é…å™¨:
  - wiktionary-cantonese    Wiktionaryç²¤è¯­è¯æ¡

ç¤ºä¾‹:
  # è½¬æ¢ Wiktionary Cantonese
  node scripts/jsonl-to-json.js \\
    --dict wiktionary-cantonese \\
    --input data/processed/wiktionary_cantonese_entries.jsonl

  # æµ‹è¯•æ¨¡å¼ï¼šåªå¤„ç†å‰1000æ¡
  node scripts/jsonl-to-json.js \\
    --dict wiktionary-cantonese \\
    --input data/processed/wiktionary_cantonese_entries.jsonl \\
    --limit 1000

  # æŒ‡å®šè¾“å‡ºè·¯å¾„
  node scripts/jsonl-to-json.js \\
    --dict wiktionary-cantonese \\
    --input data/processed/wiktionary_cantonese_entries.jsonl \\
    --output public/dictionaries/my-dict.json
  `)
}

// è¿è¡Œä¸»å‡½æ•°
main()

